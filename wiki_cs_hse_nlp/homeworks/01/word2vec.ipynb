{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.functional as F\n",
    "import torch.nn as nn\n",
    "from nltk import ngrams\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, wordpunct_tokenize, word_tokenize\n",
    "from gensim.models import KeyedVectors\n",
    "from utils import get_distinct_words, read_corpus\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n",
      "<torch.cuda.device object at 0x7fe36c86c9a0>\n"
     ]
    }
   ],
   "source": [
    "print(torch.device('cuda:1'))\n",
    "print(torch.cuda.device(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count = 2\n",
    "ru_corpus_cp = read_corpus(\"ru_copy\")\n",
    "index_to_key, word_counter = get_distinct_words(ru_corpus_cp, min_count=min_count)\n",
    "index_to_key = [\"UNK\", \"PAD\"] + index_to_key\n",
    "key_to_index = {word: i for i, word in enumerate(index_to_key)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,\n",
       " [['кстати',\n",
       "   'как',\n",
       "   'неожиданно',\n",
       "   'кпрф',\n",
       "   'становиться',\n",
       "   'не',\n",
       "   'все',\n",
       "   'равный',\n",
       "   'на',\n",
       "   'судьба',\n",
       "   'фермер',\n",
       "   'именно',\n",
       "   'накануне',\n",
       "   'выборы'],\n",
       "  ['можно',\n",
       "   'и',\n",
       "   'по',\n",
       "   'другому',\n",
       "   'сказать',\n",
       "   'убогий',\n",
       "   'клоунада',\n",
       "   'кпрф',\n",
       "   'это',\n",
       "   'попытка',\n",
       "   'отвечать',\n",
       "   'на',\n",
       "   'запрос',\n",
       "   'молодой',\n",
       "   'поколение',\n",
       "   'левый',\n",
       "   'не',\n",
       "   'питать',\n",
       "   'иллюзия',\n",
       "   'по',\n",
       "   'повод',\n",
       "   'коммунистический',\n",
       "   'номенклатура',\n",
       "   'советский',\n",
       "   'образец',\n",
       "   'но',\n",
       "   'в',\n",
       "   'сила',\n",
       "   'свой',\n",
       "   'положение',\n",
       "   'под',\n",
       "   'давление',\n",
       "   'вызов',\n",
       "   'время',\n",
       "   'они',\n",
       "   'вынуждать',\n",
       "   'быть',\n",
       "   'меняться']])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ru_corpus_cp), ru_corpus_cp[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_matrix(sequences, key_to_index, UNK=\"UNK\", PAD=\"PAD\", max_len=None):\n",
    "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
    "    if isinstance(sequences[0], str):\n",
    "        sequences = [x.split() for x in sequences]\n",
    "\n",
    "    max_sequence_len = max([len(x) for x in sequences])\n",
    "    if max_len is not None and max_sequence_len > max_len :\n",
    "        max_sequence_len = max_len\n",
    "\n",
    "    matrix = np.full((len(sequences), max_sequence_len), np.int32(key_to_index[PAD]))\n",
    "    for i, seq in enumerate(sequences):\n",
    "        row_ix = [key_to_index.get(word, key_to_index[UNK]) for word in seq[:max_sequence_len]]\n",
    "        matrix[i, :len(row_ix)] = row_ix\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "309"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(len(ru_corpus_cp))\n",
    "# display(as_matrix(ru_corpus_cp, key_to_index, max_len=10))\n",
    "len(list(chain.from_iterable(ru_corpus_cp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(lst, n):\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "def pad_text(text: list, window_size: int, pad: str):\n",
    "    appendix = [pad] * window_size\n",
    "\n",
    "    return appendix + text + appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseEmbeddings(KeyedVectors):\n",
    "    def __init__(self, corpus, distinct_words=None, word_counter=None, vector_size=100, min_count=10):\n",
    "        super().__init__(vector_size=vector_size)\n",
    "        \n",
    "        self.index_to_key = distinct_words\n",
    "        self.word_counter = word_counter\n",
    "        if distinct_words is None or word_counter is None:\n",
    "            self.index_to_key, self.word_counter = get_distinct_words(corpus, min_count=min_count)\n",
    "    \n",
    "        self.key_to_index = {word: i for i, word in enumerate(self.index_to_key)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19, 15, 12, 45,  1, 26, 43,  6,  9, 29, 28, 30,  4, 35, 32, 13,  5,\n",
       "        9, 41, 14])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(50, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(u):\n",
    "    return torch.tensor([torch.exp(u_j) / torch.sum(torch.exp(u)) for u_j in u])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_loss tensor(8.8771e+11)\n",
      "batch_loss tensor(244105.3125)\n",
      "batch_loss tensor(882273.8125)\n",
      "batch_loss tensor(10880132.)\n",
      "batch_loss tensor(17419.5645)\n",
      "batch_loss tensor(1232314.6250)\n",
      "batch_loss tensor(20.1731)\n",
      "batch_loss tensor(478.6078)\n",
      "batch_loss tensor(10292556.)\n",
      "batch_loss tensor(11262.0527)\n",
      "batch_loss tensor(4530980.5000)\n",
      "batch_loss tensor(3.5248e+08)\n",
      "batch_loss tensor(6.0777e+09)\n",
      "batch_loss tensor(19.7348)\n",
      "batch_loss tensor(1.3265e+08)\n",
      "batch_loss tensor(7652.3301)\n",
      "batch_loss tensor(167474.5000)\n",
      "batch_loss tensor(821608.8750)\n",
      "batch_loss tensor(2.3367e+08)\n",
      "batch_loss tensor(90153680.)\n",
      "batch_loss tensor(3026.3611)\n",
      "batch_loss tensor(9449.4238)\n",
      "batch_loss tensor(2982.3794)\n",
      "batch_loss tensor(13302.7979)\n",
      "batch_loss tensor(428.6572)\n",
      "batch_loss tensor(3560.0234)\n",
      "batch_loss tensor(966033.3750)\n",
      "batch_loss tensor(153.6170)\n",
      "batch_loss tensor(25465.2324)\n",
      "batch_loss tensor(188991.0156)\n",
      "batch_loss tensor(3167967.)\n",
      "batch_loss tensor(5886314.)\n",
      "batch_loss tensor(88146.8281)\n",
      "batch_loss tensor(741.4030)\n",
      "batch_loss tensor(516.1375)\n",
      "batch_loss tensor(3972667.5000)\n",
      "batch_loss tensor(874449.5625)\n",
      "batch_loss tensor(77144.7812)\n",
      "batch_loss tensor(4146683.)\n",
      "batch_loss tensor(5.9172e+10)\n",
      "batch_loss tensor(26.3142)\n",
      "batch_loss tensor(3516153.7500)\n",
      "batch_loss tensor(1998663.1250)\n",
      "batch_loss tensor(145.2904)\n",
      "batch_loss tensor(30619.5020)\n",
      "batch_loss tensor(2109.6770)\n",
      "batch_loss tensor(3838829.)\n",
      "batch_loss tensor(325144.8125)\n",
      "batch_loss tensor(1.3660e+08)\n",
      "batch_loss tensor(4.5170e+11)\n",
      "batch_loss tensor(71922320.)\n",
      "batch_loss tensor(466.9402)\n",
      "batch_loss tensor(46155172.)\n",
      "batch_loss tensor(57.9139)\n",
      "batch_loss tensor(221.3387)\n",
      "batch_loss tensor(81380.4297)\n",
      "batch_loss tensor(16624.7988)\n",
      "batch_loss tensor(2.2982e+08)\n",
      "batch_loss tensor(2.3858e+09)\n",
      "batch_loss tensor(969798.3750)\n",
      "batch_loss tensor(17185778.)\n",
      "batch_loss tensor(1323765.)\n",
      "batch_loss tensor(148.9723)\n",
      "batch_loss tensor(2.8462e+09)\n",
      "batch_loss tensor(558312.8125)\n",
      "batch_loss tensor(35364.7656)\n",
      "batch_loss tensor(4.2779e+10)\n",
      "batch_loss tensor(121.1103)\n",
      "batch_loss tensor(18306.5527)\n",
      "batch_loss tensor(2695.5786)\n",
      "batch_loss tensor(36134.8008)\n",
      "batch_loss tensor(172.7909)\n",
      "batch_loss tensor(2.3447e+08)\n",
      "batch_loss tensor(32367680.)\n",
      "batch_loss tensor(3117.7122)\n",
      "batch_loss tensor(2608.6458)\n",
      "batch_loss tensor(2711.7351)\n",
      "batch_loss tensor(6.8384e+12)\n",
      "batch_loss tensor(325315.4375)\n",
      "batch_loss tensor(2123.9160)\n",
      "batch_loss tensor(-35.3066)\n",
      "batch_loss tensor(25627.3223)\n",
      "batch_loss tensor(35185.4883)\n",
      "batch_loss tensor(339194.3125)\n",
      "batch_loss tensor(254.7356)\n",
      "batch_loss tensor(89927744.)\n",
      "batch_loss tensor(-0.5281)\n",
      "batch_loss tensor(1298.9454)\n",
      "batch_loss tensor(920973.6250)\n",
      "batch_loss "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:00<00:01,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0754e+08)\n",
      "batch_loss tensor(282485.9062)\n",
      "batch_loss tensor(1944.5731)\n",
      "batch_loss tensor(6006041.)\n",
      "batch_loss tensor(1.1148e+08)\n",
      "batch_loss tensor(7603505.)\n",
      "batch_loss tensor(2.7608e+08)\n",
      "batch_loss tensor(1.8910e+09)\n",
      "batch_loss tensor(2340993.7500)\n",
      "batch_loss tensor(585.4722)\n",
      "batch_loss tensor(6392131.)\n",
      "batch_loss tensor(1.4267e+16)\n",
      "batch_loss tensor(7716685.5000)\n",
      "batch_loss tensor(2.0248e+08)\n",
      "batch_loss tensor(7373.6377)\n",
      "batch_loss tensor(144343.9531)\n",
      "batch_loss tensor(1.1595e+10)\n",
      "batch_loss tensor(2998948.5000)\n",
      "batch_loss tensor(6.7255e+10)\n",
      "batch_loss tensor(8.8092e+08)\n",
      "batch_loss tensor(16800.5801)\n",
      "batch_loss tensor(835714.5625)\n",
      "batch_loss tensor(6.0344e+10)\n",
      "batch_loss tensor(12754989.)\n",
      "batch_loss tensor(26.0321)\n",
      "batch_loss tensor(313218.2188)\n",
      "batch_loss tensor(8593483.)\n",
      "batch_loss tensor(20280240.)\n",
      "batch_loss tensor(453090.9375)\n",
      "batch_loss tensor(28507594.)\n",
      "batch_loss tensor(2.9762e+08)\n",
      "batch_loss tensor(4611320.5000)\n",
      "batch_loss tensor(204.0508)\n",
      "batch_loss tensor(91006.3828)\n",
      "batch_loss tensor(4.1534e+09)\n",
      "batch_loss tensor(9339268.)\n",
      "batch_loss tensor(318240.7812)\n",
      "batch_loss tensor(1.3052e+08)\n",
      "batch_loss tensor(9638122.)\n",
      "batch_loss tensor(562909.9375)\n",
      "batch_loss tensor(1.1259e+16)\n",
      "batch_loss tensor(52409.6641)\n",
      "batch_loss tensor(265.9688)\n",
      "batch_loss tensor(17964500.)\n",
      "batch_loss tensor(72265032.)\n",
      "batch_loss tensor(8521.5332)\n",
      "batch_loss tensor(1764687.2500)\n",
      "batch_loss tensor(1587.2844)\n",
      "batch_loss tensor(1842936.1250)\n",
      "batch_loss tensor(-12.9100)\n",
      "batch_loss tensor(36786596.)\n",
      "batch_loss tensor(114027.6328)\n",
      "batch_loss tensor(5.1501e+09)\n",
      "batch_loss tensor(124004.2422)\n",
      "batch_loss tensor(24390.1777)\n",
      "batch_loss tensor(2028138.5000)\n",
      "batch_loss tensor(93.8930)\n",
      "batch_loss tensor(5472.5854)\n",
      "batch_loss tensor(2386592.2500)\n",
      "batch_loss tensor(11767092.)\n",
      "batch_loss tensor(92470.6328)\n",
      "batch_loss tensor(8203.1143)\n",
      "batch_loss tensor(2408.3740)\n",
      "batch_loss tensor(-3.3221)\n",
      "batch_loss tensor(-18.0113)\n",
      "batch_loss tensor(1.3882)\n",
      "batch_loss tensor(3434509.)\n",
      "batch_loss tensor(3674.5339)\n",
      "batch_loss tensor(16291925.)\n",
      "batch_loss tensor(930258.3125)\n",
      "batch_loss tensor(4892.7388)\n",
      "batch_loss tensor(363879.1875)\n",
      "batch_loss tensor(2575205.7500)\n",
      "batch_loss tensor(8995105.)\n",
      "batch_loss tensor(4421777.)\n",
      "batch_loss tensor(2.9886e+08)\n",
      "batch_loss tensor(256936.0781)\n",
      "batch_loss tensor(5786964.5000)\n",
      "batch_loss tensor(10439.5176)\n",
      "batch_loss tensor(175844.9531)\n",
      "batch_loss tensor(14135.5391)\n",
      "batch_loss tensor(1.5582e+08)\n",
      "batch_loss tensor(38647.7383)\n",
      "batch_loss tensor(110.2528)\n",
      "batch_loss tensor(36.7334)\n",
      "batch_loss tensor(2.8334e+08)\n",
      "batch_loss tensor(1002.7868)\n",
      "batch_loss tensor(4954.5317)\n",
      "batch_loss tensor(139898.5938)\n",
      "batch_loss tensor(5245485.)\n",
      "batch_loss tensor(3136.5315)\n",
      "batch_loss tensor(121.8392)\n",
      "batch_loss tensor(1172131.8750)\n",
      "batch_loss tensor(3748.8977)\n",
      "batch_loss tensor(92390408.)\n",
      "batch_loss tensor(21249514.)\n",
      "batch_loss tensor(3143.3291)\n",
      "batch_loss tensor(4334832.5000)\n",
      "batch_loss tensor(-1.1860)\n",
      "batch_loss tensor(20794.3418)\n",
      "batch_loss tensor(122901.2266)\n",
      "batch_loss tensor(33475.2969)\n",
      "batch_loss tensor(26925374.)\n",
      "batch_loss tensor(1729896.)\n",
      "batch_loss tensor(2630876.)\n",
      "batch_loss tensor(972686.8125)\n",
      "batch_loss tensor(3.3727e+08)\n",
      "batch_loss tensor(17428.3301)\n",
      "batch_loss tensor(393211.0312)\n",
      "batch_loss tensor(4.8863e+09)\n",
      "batch_loss tensor(754.3748)\n",
      "batch_loss tensor(1.3845e+12)\n",
      "batch_loss tensor(69312.0938)\n",
      "batch_loss tensor(507.5141)\n",
      "batch_loss tensor(5.4267e+09)\n",
      "batch_loss tensor(1897900.2500)\n",
      "batch_loss tensor(164.5937)\n",
      "batch_loss tensor(61.8038)\n",
      "batch_loss tensor(2.1572e+08)\n",
      "batch_loss tensor(136953.0469)\n",
      "batch_loss tensor(1136.7897)\n",
      "batch_loss tensor(4.0688e+10)\n",
      "batch_loss tensor(19347.0449)\n",
      "batch_loss tensor(9686298.)\n",
      "batch_loss tensor(9.0766e+08)\n",
      "batch_loss tensor(359.0362)\n",
      "batch_loss tensor(8246807.5000)\n",
      "batch_loss tensor(3.9186e+08)\n",
      "batch_loss tensor(10608152.)\n",
      "batch_loss tensor(14.7234)\n",
      "batch_loss tensor(590.8563)\n",
      "batch_loss tensor(2.4207e+08)\n",
      "batch_loss tensor(490812.1875)\n",
      "batch_loss tensor(25152564.)\n",
      "batch_loss tensor(81259.4375)\n",
      "batch_loss tensor(21985.3301)\n",
      "batch_loss tensor(1.0843e+08)\n",
      "batch_loss tensor(3897185.)\n",
      "batch_loss tensor(24090.7012)\n",
      "batch_loss tensor(826250.9375)\n",
      "batch_loss tensor(5680.4390)\n",
      "batch_loss tensor(32352326.)\n",
      "batch_loss tensor(1.7733e+08)\n",
      "batch_loss tensor(754.8271)\n",
      "batch_loss tensor(94625464.)\n",
      "batch_loss tensor(430948.3750)\n",
      "batch_loss tensor(3.6579e+10)\n",
      "batch_loss tensor(21678.5137)\n",
      "batch_loss tensor(2.6537e+10)\n",
      "batch_loss tensor(6723319.5000)\n",
      "batch_loss tensor(171389.3906)\n",
      "batch_loss tensor(28511.2773)\n",
      "batch_loss tensor(7749644.5000)\n",
      "batch_loss tensor(3412.2144)\n",
      "batch_loss tensor(7.4589e+10)\n",
      "batch_loss tensor(79.7051)\n",
      "batch_loss tensor(323116.5625)\n",
      "batch_loss tensor(46.6221)\n",
      "batch_loss tensor(874.7519)\n",
      "batch_loss tensor(1.4747e+12)\n",
      "batch_loss tensor(411.6747)\n",
      "batch_loss tensor(177.2621)\n",
      "batch_loss tensor(5226320.)\n",
      "batch_loss tensor(2.1202e+08)\n",
      "batch_loss tensor(29914.1855)\n",
      "batch_loss tensor(2792161.7500)\n",
      "batch_loss tensor(351.8108)\n",
      "batch_loss tensor(42006.6055)\n",
      "batch_loss tensor(204333.)\n",
      "batch_loss tensor(129641.2578)\n",
      "batch_loss tensor(150727.7500)\n",
      "batch_loss tensor(330.5570)\n",
      "batch_loss tensor(31911.6816)\n",
      "batch_loss tensor(616816.5625)\n",
      "batch_loss tensor(1.5608e+12)\n",
      "batch_loss tensor(7.2802e+08)\n",
      "batch_loss tensor(429.4468)\n",
      "batch_loss tensor(3648.8887)\n",
      "batch_loss tensor(3.3409e+08)\n",
      "batch_loss tensor(-7.1842)\n",
      "batch_loss tensor(44.1951)\n",
      "batch_loss tensor(75983600.)\n",
      "batch_loss tensor(25598.5117)\n",
      "batch_loss tensor(107262.4219)\n",
      "batch_loss tensor(5850.1890)\n",
      "batch_loss tensor(102807.9688)\n",
      "batch_loss tensor(354.4931)\n",
      "batch_loss tensor(474.9050)\n",
      "batch_loss tensor(5.3897e+09)\n",
      "batch_loss tensor(207.6434)\n",
      "batch_loss tensor(8.4032e+08)\n",
      "batch_loss tensor(3458.1028)\n",
      "batch_loss tensor(2.6554e+10)\n",
      "batch_loss tensor(1298817.7500)\n",
      "batch_loss tensor(835.0973)\n",
      "batch_loss tensor(1.1727e+08)\n",
      "batch_loss tensor(2.2684e+15)\n",
      "batch_loss tensor(61476248.)\n",
      "batch_loss tensor(652.5896)\n",
      "batch_loss tensor(16215.3213)\n",
      "batch_loss tensor(13599232.)\n",
      "batch_loss tensor(138568.3281)\n",
      "batch_loss tensor(3761880.5000)\n",
      "batch_loss tensor(9871.7598)\n",
      "batch_loss tensor(4831.8521)\n",
      "batch_loss tensor(14.6190)\n",
      "batch_loss tensor(6413221.5000)\n",
      "batch_loss tensor(750061.3750)\n",
      "batch_loss tensor(1931.5242)\n",
      "batch_loss tensor(2189.6077)\n",
      "batch_loss tensor(40442.5547)\n",
      "batch_loss tensor(98.3412)\n",
      "batch_loss tensor(5.7931e+08)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:00<00:00,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_loss tensor(2.2951e+09)\n",
      "batch_loss tensor(9699.6426)\n",
      "batch_loss tensor(1.7965e+08)\n",
      "batch_loss tensor(789416.3125)\n",
      "batch_loss tensor(-8.8743)\n",
      "batch_loss tensor(230.2584)\n",
      "batch_loss tensor(1320636.2500)\n",
      "batch_loss tensor(-24.8871)\n",
      "batch_loss tensor(74949400.)\n",
      "batch_loss tensor(194850.2969)\n",
      "batch_loss tensor(55257536.)\n",
      "batch_loss tensor(171569.0156)\n",
      "batch_loss tensor(7151126.)\n",
      "batch_loss tensor(15727734.)\n",
      "batch_loss tensor(42583.9609)\n",
      "batch_loss tensor(8.0454e+08)\n",
      "batch_loss tensor(22.2901)\n",
      "batch_loss tensor(1.2108e+09)\n",
      "batch_loss tensor(1.4062e+12)\n",
      "batch_loss tensor(157913.7500)\n",
      "batch_loss tensor(16131515.)\n",
      "batch_loss tensor(1.1990e+08)\n",
      "batch_loss tensor(208952.2344)\n",
      "batch_loss tensor(283063.1875)\n",
      "batch_loss tensor(77199080.)\n",
      "batch_loss tensor(14821.4453)\n",
      "batch_loss tensor(16995710.)\n",
      "batch_loss tensor(11132824.)\n",
      "batch_loss tensor(47326.3203)\n",
      "batch_loss tensor(7.7163e+08)\n",
      "batch_loss tensor(1258.5000)\n",
      "batch_loss tensor(233924.4219)\n",
      "batch_loss tensor(7561.5356)\n",
      "batch_loss tensor(29150504.)\n",
      "batch_loss tensor(462.4363)\n",
      "batch_loss tensor(2846.0171)\n",
      "batch_loss tensor(17020448.)\n",
      "batch_loss tensor(65710584.)\n",
      "batch_loss tensor(153.3484)\n",
      "batch_loss tensor(5440.2515)\n",
      "batch_loss tensor(94128592.)\n",
      "batch_loss tensor(1.2496e+11)\n",
      "batch_loss tensor(14053.3828)\n",
      "batch_loss tensor(27108274.)\n",
      "batch_loss tensor(1087641.5000)\n",
      "batch_loss tensor(2748450.7500)\n",
      "batch_loss tensor(174487.3281)\n",
      "batch_loss tensor(184978.0312)\n",
      "batch_loss tensor(773429.4375)\n",
      "batch_loss tensor(491.7128)\n",
      "batch_loss tensor(325518.4375)\n",
      "batch_loss tensor(3068.6763)\n",
      "batch_loss tensor(2295460.2500)\n",
      "batch_loss tensor(112048.5156)\n",
      "batch_loss tensor(5256.3940)\n",
      "batch_loss tensor(51130600.)\n",
      "batch_loss tensor(13981105.)\n",
      "batch_loss tensor(1433.4592)\n",
      "batch_loss tensor(26864422.)\n",
      "batch_loss tensor(1.6575e+11)\n",
      "batch_loss tensor(8612.8633)\n",
      "batch_loss tensor(50341292.)\n",
      "batch_loss tensor(208595.5781)\n",
      "batch_loss tensor(35951.4531)\n",
      "batch_loss tensor(280552.)\n",
      "batch_loss tensor(518741.4375)\n",
      "batch_loss tensor(25817.3965)\n",
      "batch_loss tensor(1.9665e+08)\n",
      "batch_loss tensor(513.8574)\n",
      "batch_loss tensor(98193904.)\n",
      "batch_loss tensor(4.7001e+08)\n",
      "batch_loss tensor(5.4247)\n",
      "batch_loss tensor(37284276.)\n",
      "batch_loss tensor(3.8871e+12)\n",
      "batch_loss tensor(-6.7351)\n",
      "batch_loss tensor(359.5675)\n",
      "batch_loss tensor(18651.5371)\n",
      "batch_loss tensor(1.6191e+11)\n",
      "batch_loss tensor(19606.9375)\n",
      "batch_loss tensor(91679.9219)\n",
      "batch_loss tensor(6076.2295)\n",
      "batch_loss tensor(14.3787)\n",
      "batch_loss tensor(171031.5938)\n",
      "batch_loss tensor(2474827.)\n",
      "batch_loss tensor(5131.3584)\n",
      "batch_loss tensor(2668623.)\n",
      "batch_loss tensor(313.2930)\n",
      "batch_loss tensor(1269101.7500)\n",
      "batch_loss tensor(10.0344)\n",
      "batch_loss tensor(20674.3555)\n",
      "batch_loss tensor(14660.9873)\n",
      "batch_loss tensor(2.1080e+10)\n",
      "batch_loss tensor(403127.4375)\n",
      "batch_loss tensor(5222871.5000)\n",
      "batch_loss tensor(70.6026)\n",
      "batch_loss tensor(674752.7500)\n",
      "batch_loss tensor(225298.6719)\n",
      "batch_loss tensor(13377482.)\n",
      "batch_loss tensor(197.0325)\n",
      "batch_loss tensor(1968.1260)\n",
      "batch_loss tensor(2.1484e+10)\n",
      "batch_loss tensor(33991164.)\n",
      "batch_loss tensor(2.4002e+09)\n",
      "batch_loss tensor(34.1231)\n",
      "batch_loss tensor(4.5289e+09)\n",
      "batch_loss tensor(10304721.)\n",
      "batch_loss tensor(402.1708)\n",
      "batch_loss tensor(151013.2031)\n",
      "batch_loss tensor(2322.0181)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:00<00:00,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_loss tensor(370.2365)\n",
      "batch_loss tensor(23559.2793)\n",
      "batch_loss tensor(27.8494)\n",
      "batch_loss tensor(-3.7296)\n",
      "batch_loss tensor(1.3612e+09)\n",
      "batch_loss tensor(238.9479)\n",
      "batch_loss tensor(6.2501e+09)\n",
      "batch_loss tensor(5.5691)\n",
      "batch_loss tensor(396312.9062)\n",
      "batch_loss tensor(1406.6423)\n",
      "batch_loss tensor(247832.2344)\n",
      "batch_loss tensor(26778908.)\n",
      "batch_loss tensor(3.9276e+08)\n",
      "batch_loss tensor(201.0893)\n",
      "batch_loss tensor(8451.4395)\n",
      "batch_loss tensor(2381.2583)\n",
      "batch_loss tensor(248938.3281)\n",
      "batch_loss tensor(220.0569)\n",
      "batch_loss tensor(574.6126)\n",
      "batch_loss tensor(469718.3750)\n",
      "batch_loss tensor(59684820.)\n",
      "batch_loss tensor(80.1669)\n",
      "batch_loss tensor(4478171.)\n",
      "batch_loss tensor(4087028.7500)\n",
      "batch_loss tensor(5.5426e+09)\n",
      "batch_loss tensor(2555.9194)\n",
      "batch_loss tensor(42.9979)\n",
      "batch_loss tensor(1.6584e+08)\n",
      "batch_loss tensor(1230.5305)\n",
      "batch_loss tensor(1979324.5000)\n",
      "batch_loss tensor(49438.2188)\n",
      "batch_loss tensor(3993263.)\n",
      "batch_loss tensor(8.5419)\n",
      "batch_loss tensor(60192568.)\n",
      "batch_loss tensor(73421872.)\n",
      "batch_loss tensor(4769845.5000)\n",
      "batch_loss tensor(14196.6611)\n",
      "batch_loss tensor(1111.5421)\n",
      "batch_loss tensor(1563654.8750)\n",
      "batch_loss tensor(461927.9688)\n",
      "batch_loss tensor(205649.8594)\n",
      "batch_loss tensor(6141809.5000)\n",
      "batch_loss tensor(17622.7422)\n",
      "batch_loss tensor(2886.8455)\n",
      "batch_loss tensor(310996.3125)\n",
      "batch_loss tensor(225535.3281)\n",
      "batch_loss tensor(168.4062)\n",
      "batch_loss tensor(1.7991e+10)\n",
      "batch_loss tensor(761469.1875)\n",
      "batch_loss tensor(2166726.7500)\n",
      "batch_loss tensor(13125.8701)\n",
      "batch_loss tensor(32861608.)\n",
      "batch_loss tensor(5.0914e+08)\n",
      "batch_loss tensor(1.1491)\n",
      "batch_loss tensor(21818.7598)\n",
      "batch_loss tensor(2642504.)\n",
      "batch_loss tensor(5706981.5000)\n",
      "batch_loss tensor(5.4354e+11)\n",
      "batch_loss tensor(34043796.)\n",
      "batch_loss tensor(94318648.)\n",
      "batch_loss tensor(252.4490)\n",
      "batch_loss tensor(1.5226e+10)\n",
      "batch_loss tensor(2939908.)\n",
      "batch_loss tensor(282850.4062)\n",
      "batch_loss tensor(3.5927e+09)\n",
      "batch_loss tensor(54519396.)\n",
      "batch_loss tensor(2495982.5000)\n",
      "batch_loss tensor(49994.0742)\n",
      "batch_loss tensor(20697196.)\n",
      "batch_loss tensor(2.8047e+09)\n",
      "batch_loss tensor(13468.3213)\n",
      "batch_loss tensor(63818272.)\n",
      "batch_loss tensor(5699.4097)\n",
      "batch_loss tensor(217350.7656)\n",
      "batch_loss tensor(3.9336e+12)\n",
      "batch_loss tensor(1311.2701)\n",
      "batch_loss tensor(36117764.)\n",
      "batch_loss tensor(62504.3438)\n",
      "batch_loss tensor(1994183.)\n",
      "batch_loss tensor(-1.1883)\n",
      "batch_loss tensor(349.4911)\n",
      "batch_loss tensor(21648640.)\n",
      "batch_loss tensor(88877296.)\n",
      "batch_loss tensor(222148.8125)\n",
      "batch_loss tensor(1007965.1250)\n",
      "batch_loss tensor(196.9359)\n",
      "batch_loss tensor(8722.0742)\n",
      "batch_loss tensor(64582524.)\n",
      "batch_loss tensor(1.5625e+09)\n",
      "batch_loss tensor(623370.8125)\n",
      "batch_loss tensor(151.4419)\n",
      "batch_loss tensor(30082026.)\n",
      "batch_loss tensor(524980.3750)\n",
      "batch_loss tensor(960772.8125)\n",
      "batch_loss tensor(111180.2188)\n",
      "batch_loss tensor(11911833.)\n",
      "batch_loss tensor(3.2753e+11)\n",
      "batch_loss tensor(4346.9917)\n",
      "batch_loss tensor(24.7151)\n",
      "batch_loss tensor(346.5989)\n",
      "batch_loss tensor(44457.9922)\n",
      "batch_loss tensor(152.0595)\n",
      "batch_loss tensor(1072356.1250)\n",
      "batch_loss tensor(1676.6113)\n",
      "batch_loss tensor(40.6336)\n",
      "batch_loss tensor(1.1494e+08)\n",
      "batch_loss tensor(108.8956)\n",
      "batch_loss tensor(42.5574)\n",
      "batch_loss tensor(718.2121)\n",
      "batch_loss tensor(24798640.)\n",
      "batch_loss tensor(181035.5469)\n",
      "batch_loss tensor(1829.7175)\n",
      "batch_loss tensor(1076164.5000)\n",
      "batch_loss tensor(19.3031)\n",
      "batch_loss tensor(250134.6094)\n",
      "batch_loss tensor(1318220.5000)\n",
      "batch_loss tensor(798.4739)\n",
      "batch_loss tensor(2901.5378)\n",
      "batch_loss tensor(10852671.)\n",
      "batch_loss tensor(31.5260)\n",
      "batch_loss tensor(3.9945e+12)\n",
      "batch_loss tensor(2355235.5000)\n",
      "batch_loss tensor(106370.3203)\n",
      "batch_loss tensor(526.2485)\n",
      "batch_loss tensor(2.8069e+08)\n",
      "batch_loss tensor(26105.0996)\n",
      "batch_loss tensor(19.4798)\n",
      "batch_loss tensor(14536.6416)\n",
      "batch_loss tensor(41.3217)\n",
      "batch_loss tensor(16377878.)\n",
      "batch_loss tensor(31354.1719)\n",
      "batch_loss tensor(258.5797)\n",
      "batch_loss tensor(17737246.)\n",
      "batch_loss tensor(158060.2656)\n",
      "batch_loss tensor(1.0983e+08)\n",
      "batch_loss tensor(55882.3320)\n",
      "batch_loss tensor(5.0158e+10)\n",
      "batch_loss tensor(20665.5488)\n",
      "batch_loss tensor(1.7139e+10)\n",
      "batch_loss tensor(33387.5117)\n",
      "batch_loss tensor(34.2757)\n",
      "batch_loss tensor(195044.0312)\n",
      "batch_loss tensor(29982.7891)\n",
      "batch_loss tensor(55791424.)\n",
      "batch_loss tensor(8.2133e+08)\n",
      "batch_loss tensor(2481.7190)\n",
      "batch_loss tensor(372055.4375)\n",
      "batch_loss tensor(448380.0625)\n",
      "batch_loss tensor(28081.5273)\n",
      "batch_loss tensor(8001388.5000)\n",
      "batch_loss tensor(49.8245)\n",
      "batch_loss tensor(1.9853e+09)\n",
      "batch_loss tensor(13509885.)\n",
      "batch_loss tensor(2.6405e+08)\n",
      "batch_loss tensor(3689.2375)\n",
      "batch_loss tensor(13300277.)\n",
      "batch_loss tensor(454.9242)\n",
      "batch_loss tensor(-5.1860)\n",
      "batch_loss tensor(270769.1562)\n",
      "batch_loss tensor(19574.7773)\n",
      "batch_loss "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:01<00:00,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1215e+08)\n",
      "batch_loss tensor(2471.8960)\n",
      "batch_loss tensor(44145.7344)\n",
      "batch_loss tensor(39.5793)\n",
      "batch_loss tensor(259235.6562)\n",
      "batch_loss tensor(85375.4375)\n",
      "batch_loss tensor(9.9356e+13)\n",
      "batch_loss tensor(2043103.2500)\n",
      "batch_loss tensor(7430732.)\n",
      "batch_loss tensor(656662.7500)\n",
      "batch_loss tensor(23.8300)\n",
      "batch_loss tensor(3078.3796)\n",
      "batch_loss tensor(36.5990)\n",
      "batch_loss tensor(1578344.2500)\n",
      "batch_loss tensor(1.8300e+10)\n",
      "batch_loss tensor(3301860.2500)\n",
      "batch_loss tensor(3325257.2500)\n",
      "batch_loss tensor(1323.3457)\n",
      "batch_loss tensor(8.8730e+09)\n",
      "batch_loss tensor(2511521.5000)\n",
      "batch_loss tensor(332.4497)\n",
      "batch_loss tensor(5.5875e+09)\n",
      "batch_loss tensor(2.0446e+10)\n",
      "batch_loss tensor(1358547.1250)\n",
      "batch_loss tensor(4093.9187)\n",
      "batch_loss tensor(2416478.)\n",
      "batch_loss tensor(949171.1875)\n",
      "batch_loss tensor(32138978.)\n",
      "batch_loss tensor(294.6530)\n",
      "batch_loss tensor(19428034.)\n",
      "batch_loss tensor(0.3343)\n",
      "batch_loss tensor(763.2670)\n",
      "batch_loss tensor(10989370.)\n",
      "batch_loss tensor(323.8268)\n",
      "batch_loss tensor(6114.9971)\n",
      "batch_loss tensor(480329.2500)\n",
      "batch_loss tensor(3.0769e+08)\n",
      "batch_loss tensor(2425103.7500)\n",
      "batch_loss tensor(64937304.)\n",
      "batch_loss tensor(6.8732e+09)\n",
      "batch_loss tensor(516187.2188)\n",
      "batch_loss tensor(142187.5938)\n",
      "batch_loss tensor(1.2384e+13)\n",
      "batch_loss tensor(-6.9508)\n",
      "batch_loss tensor(2662455.5000)\n",
      "batch_loss tensor(2403131.2500)\n",
      "batch_loss tensor(1026857.)\n",
      "batch_loss tensor(31382860.)\n",
      "batch_loss tensor(1387450.6250)\n",
      "batch_loss tensor(89.9579)\n",
      "batch_loss tensor(-17.7317)\n",
      "batch_loss tensor(34600096.)\n",
      "batch_loss tensor(396118.5938)\n",
      "batch_loss tensor(35705.3008)\n",
      "batch_loss tensor(1.9682e+11)\n",
      "batch_loss tensor(55485192.)\n",
      "batch_loss tensor(3172.6719)\n",
      "batch_loss tensor(3.9740e+08)\n",
      "batch_loss tensor(4.4678e+08)\n",
      "batch_loss tensor(345138.0312)\n",
      "batch_loss tensor(1.6237e+09)\n",
      "batch_loss tensor(43821200.)\n",
      "batch_loss tensor(-23.6464)\n",
      "batch_loss tensor(22655.4707)\n",
      "batch_loss tensor(691093.9375)\n",
      "batch_loss tensor(87.0083)\n",
      "batch_loss tensor(4942801.)\n",
      "batch_loss tensor(93335056.)\n",
      "batch_loss tensor(146422.3125)\n",
      "batch_loss tensor(1.0297e+11)\n",
      "batch_loss tensor(979453.1250)\n",
      "batch_loss tensor(2.9969e+10)\n",
      "batch_loss tensor(140173.3125)\n",
      "batch_loss tensor(209101.2812)\n",
      "batch_loss tensor(231671.8594)\n",
      "batch_loss tensor(694498.3125)\n",
      "batch_loss tensor(-17.9801)\n",
      "batch_loss tensor(16.2444)\n",
      "batch_loss tensor(4068.1716)\n",
      "batch_loss tensor(277041.0312)\n",
      "batch_loss tensor(38426144.)\n",
      "batch_loss tensor(548032.5625)\n",
      "batch_loss tensor(5078010.)\n",
      "batch_loss tensor(1435993.7500)\n",
      "batch_loss tensor(0.0574)\n",
      "batch_loss tensor(5593.4175)\n",
      "batch_loss tensor(33808424.)\n",
      "batch_loss tensor(6.2510e+10)\n",
      "batch_loss tensor(755.9873)\n",
      "batch_loss tensor(4398764.5000)\n",
      "batch_loss tensor(775814.3750)\n",
      "batch_loss tensor(1554587.2500)\n",
      "batch_loss tensor(4.7330e+08)\n",
      "batch_loss tensor(322208.6250)\n",
      "batch_loss tensor(9872.4004)\n",
      "batch_loss tensor(696797.1875)\n",
      "batch_loss tensor(14841.4443)\n",
      "batch_loss tensor(3148949.5000)\n",
      "batch_loss tensor(634.9591)\n",
      "batch_loss tensor(145.5958)\n",
      "batch_loss tensor(1850982.5000)\n",
      "batch_loss tensor(5748514.5000)\n",
      "batch_loss tensor(122455.3906)\n",
      "batch_loss tensor(55.7002)\n",
      "batch_loss tensor(1230.0544)\n",
      "batch_loss tensor(26705562.)\n",
      "batch_loss tensor(411787.9375)\n",
      "batch_loss tensor(244713.8750)\n",
      "batch_loss tensor(1194237.8750)\n",
      "batch_loss tensor(13320.2461)\n",
      "batch_loss tensor(4.1031e+08)\n",
      "batch_loss tensor(126441.6719)\n",
      "batch_loss tensor(3813396.2500)\n",
      "batch_loss tensor(33804624.)\n",
      "batch_loss tensor(306910.5312)\n",
      "batch_loss tensor(17587.4648)\n",
      "batch_loss tensor(703.5850)\n",
      "batch_loss tensor(294324.3438)\n",
      "batch_loss tensor(43412.1055)\n",
      "batch_loss tensor(9.1256e+08)\n",
      "batch_loss tensor(255929.1250)\n",
      "batch_loss tensor(13.2455)\n",
      "batch_loss tensor(11902.9033)\n",
      "batch_loss tensor(6649.5044)\n",
      "batch_loss tensor(250.6625)\n",
      "batch_loss tensor(33919572.)\n",
      "batch_loss tensor(53451.2812)\n",
      "batch_loss tensor(1627575.)\n",
      "batch_loss tensor(968935.0625)\n",
      "batch_loss tensor(38.4753)\n",
      "batch_loss tensor(557506.3750)\n",
      "batch_loss tensor(22203928.)\n",
      "batch_loss tensor(53026.0898)\n",
      "batch_loss tensor(2953445.)\n",
      "batch_loss tensor(27484770.)\n",
      "batch_loss tensor(1102153.1250)\n",
      "batch_loss tensor(8120.0039)\n",
      "batch_loss tensor(1.1006e+08)\n",
      "batch_loss tensor(13145506.)\n",
      "batch_loss tensor(11680550.)\n",
      "batch_loss tensor(1345183.7500)\n",
      "batch_loss tensor(10090.3633)\n",
      "batch_loss tensor(4.7637e+10)\n",
      "batch_loss tensor(39.0519)\n",
      "batch_loss tensor(7775851.5000)\n",
      "batch_loss tensor(8961.5791)\n",
      "batch_loss tensor(35.8984)\n",
      "batch_loss tensor(324464.2188)\n",
      "batch_loss tensor(1946684.8750)\n",
      "batch_loss tensor(3561988.7500)\n",
      "batch_loss tensor(570378.5625)\n",
      "batch_loss tensor(5181976.)\n",
      "batch_loss tensor(33.4550)\n",
      "batch_loss tensor(524875.4375)\n",
      "batch_loss tensor(402.0781)\n",
      "batch_loss tensor(25964.7852)\n",
      "batch_loss tensor(69193.7812)\n",
      "batch_loss tensor(29861.5645)\n",
      "batch_loss tensor(11091.8145)\n",
      "batch_loss tensor(8451017.)\n",
      "batch_loss tensor(752274.5000)\n",
      "batch_loss tensor(8.7247e+08)\n",
      "batch_loss tensor(36102.0742)\n",
      "batch_loss tensor(57.2540)\n",
      "batch_loss tensor(5.9373e+08)\n",
      "batch_loss tensor(-8.0963)\n",
      "batch_loss tensor(8748112.)\n",
      "batch_loss tensor(169303.2188)\n",
      "batch_loss tensor(360435.2500)\n",
      "batch_loss tensor(12002.3389)\n",
      "batch_loss tensor(8949703.)\n",
      "batch_loss tensor(5105.6157)\n",
      "batch_loss tensor(1870328.2500)\n",
      "batch_loss tensor(372.1355)\n",
      "batch_loss tensor(4.5822e+09)\n",
      "batch_loss tensor(1218281.6250)\n",
      "batch_loss tensor(17720.2109)\n",
      "batch_loss tensor(227540.0312)\n",
      "batch_loss tensor(1.0708e+09)\n",
      "batch_loss tensor(692526.8750)\n",
      "batch_loss tensor(6874038.5000)\n",
      "batch_loss tensor(85384.3828)\n",
      "batch_loss tensor(6569.1421)\n",
      "batch_loss tensor(34574740.)\n",
      "batch_loss tensor(88.8827)\n",
      "batch_loss tensor(4426193.5000)\n",
      "batch_loss tensor(-5.3383)\n",
      "batch_loss tensor(7042704.)\n",
      "batch_loss tensor(13951239.)\n",
      "batch_loss tensor(153054.8906)\n",
      "batch_loss tensor(18433.0645)\n",
      "batch_loss tensor(2142053.2500)\n",
      "batch_loss tensor(462552.9688)\n",
      "batch_loss tensor(1483226.1250)\n",
      "batch_loss tensor(91.7074)\n",
      "batch_loss tensor(3336.2932)\n",
      "batch_loss tensor(732273.5625)\n",
      "batch_loss tensor(15074.4199)\n",
      "batch_loss tensor(5.9434e+08)\n",
      "batch_loss tensor(1.0801e+10)\n",
      "batch_loss tensor(2453155.)\n",
      "batch_loss tensor(13093877.)\n",
      "batch_loss tensor(16250.3594)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_loss tensor(24203798.)\n",
      "batch_loss tensor(63512180.)\n",
      "batch_loss tensor(62321172.)\n",
      "batch_loss tensor(227462.4531)\n",
      "batch_loss tensor(1729.5999)\n",
      "batch_loss tensor(3090278.5000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class Word2Vec(BaseEmbeddings):\n",
    "    def __init__(self, corpus, distinct_words=None, vector_size=100, window_size=5,\n",
    "                 min_count=10, batch_size=None, n_negative=5, n_epoches=5):\n",
    "        super().__init__(corpus, vector_size=vector_size, distinct_words=distinct_words, min_count=min_count)\n",
    "\n",
    "        self.W1 = torch.randn((len(self.index_to_key), vector_size))  # vocab_size, vector_size    #, device=torch.cuda.device(0))\n",
    "        self.W2 = torch.randn((vector_size, len(self.index_to_key)))  # vector_size, vocab_size    #, device=torch.cuda.device(0))\n",
    "        # self.emb = nn.Embedding(len(self.index_to_key), vector_size)\n",
    "        # self.exp = nn.Linear(vector_size, len(self.index_to_key))\n",
    "\n",
    "        self.corpus = corpus\n",
    "        self.window_size = window_size\n",
    "        self.batch_size = batch_size\n",
    "        if batch_size is None:\n",
    "            self.batch_size = np.max([len(text) for text in corpus])\n",
    "        self.n_negative = n_negative\n",
    "        self.alpha = 0.001\n",
    "        \n",
    "        self.train(n_epoches)\n",
    "        self.vectors = self.W1\n",
    "\n",
    "    def one_hot_vector(self, word: str):\n",
    "        vector = torch.zeros(len(self.index_to_key))\n",
    "        vector[self.key_to_index[word]] = 1\n",
    "\n",
    "        return vector\n",
    "    \n",
    "\n",
    "    def train(self, n_epoches=5):\n",
    "        \"\"\"\n",
    "        trains self.center_W and self.context_W matrices\n",
    "        \"\"\"\n",
    "        for epoch in tqdm(range(n_epoches)):\n",
    "            for text in self.corpus:\n",
    "                for batch in chunks(text, self.batch_size):\n",
    "                    batch_loss = 0\n",
    "\n",
    "                    for j, center in enumerate(batch):\n",
    "                        if center in self.index_to_key:\n",
    "\n",
    "                            window = [batch[i] for i in range(-self.window_size, self.window_size + 1, 1) if i + j >= 0 and i + j < len(batch) and j != 0 and batch[i] in self.index_to_key] \n",
    "                            \n",
    "                            h = self.one_hot_vector(center) @ self.W1      # 1, vocab_size x vocab_size, vec_size = 1, vec_size\n",
    "                            # print(\"h\", h.shape)\n",
    "                            u = h @ self.W2                                # 1, vec_size x vec_size, vocab_size = 1, voc_size\n",
    "                            # print(\"u\", u.shape)\n",
    "                            y = softmax(u)\n",
    "                            # print(\"y\", y.shape)\n",
    "                            k_neg = np.random.choice(len(self.index_to_key), self.n_negative)\n",
    "                            W2_neg = self.W2[:, k_neg]                     # vec_size, k_neg  \n",
    "                            # print(\"W2_neg\", W2_neg.shape)\n",
    "                            neg_sum = torch.sum(torch.exp(h @ W2_neg))\n",
    "                            # print(\"neg_sum\", neg_sum)\n",
    "                            # print(window)\n",
    "                            u_c = torch.sum(torch.tensor([h @ self.W2[:, self.key_to_index[context]] for context in window]))  # 1, vec_size x vec_size, 1\n",
    "\n",
    "                            batch_loss = -u_c + self.n_negative * neg_sum\n",
    "                            print(\"batch_loss\", batch_loss)\n",
    "\n",
    "                            t = torch.zeros_like(y)\n",
    "                            t[k_neg] = 1\n",
    "                            # print(t)\n",
    "                            dl_du = -t + y  # 1, voc_size\n",
    "                            dl_dW2 = h.view(-1, 1) @ dl_du.view(1, -1)  # vec_size, 1 x 1, voc_size\n",
    "                    \n",
    "                            dl_dh = dl_du.view(1, -1) @ self.W2.T  # 1, voc_size x vec_size, voc_size\n",
    "                            dl_dW1 = self.one_hot_vector(center).view(-1, 1) @ dl_dh  # voc_size, 1 x 1, vec_size\n",
    "\n",
    "                            # print(dl_dW1.shape, dl_dW2.shape)\n",
    "\n",
    "\n",
    "                            # e = np.zeros(len(self.index_to_key))\n",
    "                            \n",
    "\n",
    "                            # dot_U_V = self.U[self.key_to_index[context]] @ self.V[self.key_to_index[center]]  # vec_size x vec_size = 1\n",
    "                            # dot_U_V = \n",
    "                            # print(dot_U_V)\n",
    "                    \n",
    "                            # k_neg = np.random.choice(len(self.index_to_key), self.n_negative)\n",
    "                            # dot_Uneg_V = self.U[k_neg] @ self.V[self.key_to_index[center]]  # k_neg, vec_size x vec_size, 1 = k_neg, 1\n",
    "                            # exp_Uneg_V = torch.expm1(dot_Uneg_V)\n",
    "                            # print(exp_Uneg_V)\n",
    "                            # loss_ij = -dot_U_V + torch.sum(exp_Uneg_V, axis=0)\n",
    "                        \n",
    "                            # batch_loss += loss_ij\n",
    "                            # print(batch_loss)\n",
    "                            \n",
    "                            # dL_dV = torch.sum(-self.U[self.key_to_index[context]] + torch.sum(exp_Uneg_V.view(-1, 1) * self.U[self.key_to_index[center]], axis=0))\n",
    "                            # dL_dU = torch.sum(-self.V[self.key_to_index[center]] + torch.sum(exp_Uneg_V.view(-1, 1) * self.V[self.key_to_index[center]], axis=0))\n",
    "\n",
    "                            self.W1 -= self.alpha * dl_dW1\n",
    "                            self.W2 -= self.alpha * dl_dW2\n",
    "\n",
    "                    # print(batch_loss)\n",
    "\n",
    "                # break\n",
    "            # break\n",
    "\n",
    "\n",
    "w2v = Word2Vec(ru_corpus_cp, min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2165, -1.4011, -0.5845, -0.3900,  0.4657],\n",
      "        [-0.9166,  0.2588, -0.9368,  0.6109,  1.8453],\n",
      "        [-0.8238,  0.1415, -0.8317, -0.0836,  0.3332],\n",
      "        [ 0.6532,  0.8278,  1.7981, -0.5450,  0.7319],\n",
      "        [-0.5642, -1.0860, -0.7013, -0.1075,  1.2076],\n",
      "        [ 0.6756, -1.0019,  1.4159, -0.3987,  0.1787],\n",
      "        [-0.4165, -1.3151, -0.9172,  0.3943, -0.0899],\n",
      "        [-0.2833, -0.8074,  0.0502,  1.3422,  0.4793],\n",
      "        [ 0.5246, -0.7201, -1.1037,  0.0930, -0.2626],\n",
      "        [-0.5134,  1.1586, -1.5844,  1.5967, -0.0292]])\n",
      "[6 9 3]\n",
      "tensor([-2.6095, -2.1787,  3.7570])\n"
     ]
    }
   ],
   "source": [
    "U = torch.randn((len(index_to_key[:10]), 5))\n",
    "V = torch.randn((len(index_to_key[:10]), 5))\n",
    "neg = np.random.choice(len(index_to_key[:10]), 3)\n",
    "print(U)\n",
    "print(neg)\n",
    "print(U[neg] @ V[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,  10,  20,  30,  40,  50,  60,  70,  80,  90, 100, 110, 120, 130,\n",
       "        140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250, 260, 270,\n",
       "        280, 290, 300, 310, 320, 330, 340, 350, 360, 370, 380, 390, 400, 410,\n",
       "        420, 430, 440, 450, 460, 470, 480, 490, 500, 510, 520, 530, 540, 550,\n",
       "        560, 570, 580, 590, 600, 610, 620, 630, 640, 650, 660, 670, 680, 690,\n",
       "        700, 710, 720, 730, 740, 750, 760, 770, 780, 790, 800, 810, 820, 830,\n",
       "        840, 850, 860, 870, 880, 890, 900, 910, 920, 930, 940, 950, 960, 970,\n",
       "        980, 990])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum((torch.arange(5).view(-1, 1) * torch.arange(100)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 2, 4, 5, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Word2VecDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Takes a HuggingFace dataset as an input, to be used for a Word2Vec dataloader.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, vocab_size):\n",
    "        self.dataset = dataset\n",
    "        self.vocab_size = vocab_size\n",
    "        self.data = [i for s in dataset['moving_window'] for i in s]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
