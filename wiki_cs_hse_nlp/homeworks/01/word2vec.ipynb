{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.functional as F\n",
    "import torch.nn as nn\n",
    "from nltk import ngrams\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, wordpunct_tokenize, word_tokenize\n",
    "from gensim.models import KeyedVectors\n",
    "from utils import get_distinct_words, read_corpus\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n",
      "<torch.cuda.device object at 0x7f6d10e5ace0>\n"
     ]
    }
   ],
   "source": [
    "print(torch.device('cuda:1'))\n",
    "print(torch.cuda.device(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count = 2\n",
    "ru_corpus_cp = read_corpus(\"ru_copy\")\n",
    "index_to_key, word_counter = get_distinct_words(ru_corpus_cp, min_count=min_count)\n",
    "index_to_key = [\"UNK\", \"PAD\"] + index_to_key\n",
    "key_to_index = {word: i for i, word in enumerate(index_to_key)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,\n",
       " [['кстати',\n",
       "   'как',\n",
       "   'неожиданно',\n",
       "   'кпрф',\n",
       "   'становиться',\n",
       "   'не',\n",
       "   'все',\n",
       "   'равный',\n",
       "   'на',\n",
       "   'судьба',\n",
       "   'фермер',\n",
       "   'именно',\n",
       "   'накануне',\n",
       "   'выборы'],\n",
       "  ['можно',\n",
       "   'и',\n",
       "   'по',\n",
       "   'другому',\n",
       "   'сказать',\n",
       "   'убогий',\n",
       "   'клоунада',\n",
       "   'кпрф',\n",
       "   'это',\n",
       "   'попытка',\n",
       "   'отвечать',\n",
       "   'на',\n",
       "   'запрос',\n",
       "   'молодой',\n",
       "   'поколение',\n",
       "   'левый',\n",
       "   'не',\n",
       "   'питать',\n",
       "   'иллюзия',\n",
       "   'по',\n",
       "   'повод',\n",
       "   'коммунистический',\n",
       "   'номенклатура',\n",
       "   'советский',\n",
       "   'образец',\n",
       "   'но',\n",
       "   'в',\n",
       "   'сила',\n",
       "   'свой',\n",
       "   'положение',\n",
       "   'под',\n",
       "   'давление',\n",
       "   'вызов',\n",
       "   'время',\n",
       "   'они',\n",
       "   'вынуждать',\n",
       "   'быть',\n",
       "   'меняться']])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ru_corpus_cp), ru_corpus_cp[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_matrix(sequences, key_to_index, UNK=\"UNK\", PAD=\"PAD\", max_len=None):\n",
    "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
    "    if isinstance(sequences[0], str):\n",
    "        sequences = [x.split() for x in sequences]\n",
    "\n",
    "    max_sequence_len = max([len(x) for x in sequences])\n",
    "    if max_len is not None and max_sequence_len > max_len :\n",
    "        max_sequence_len = max_len\n",
    "\n",
    "    matrix = np.full((len(sequences), max_sequence_len), np.int32(key_to_index[PAD]))\n",
    "    for i, seq in enumerate(sequences):\n",
    "        row_ix = [key_to_index.get(word, key_to_index[UNK]) for word in seq[:max_sequence_len]]\n",
    "        matrix[i, :len(row_ix)] = row_ix\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "309"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(len(ru_corpus_cp))\n",
    "# display(as_matrix(ru_corpus_cp, key_to_index, max_len=10))\n",
    "len(list(chain.from_iterable(ru_corpus_cp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseEmbeddings(KeyedVectors):\n",
    "    def __init__(self, corpus, distinct_words=None, word_counter=None, vector_size=100, min_count=10):\n",
    "        super().__init__(vector_size=vector_size)\n",
    "        \n",
    "        self.index_to_key = distinct_words\n",
    "        self.word_counter = word_counter\n",
    "        if distinct_words is None or word_counter is None:\n",
    "            self.index_to_key, self.word_counter = get_distinct_words(corpus, min_count=min_count)\n",
    "    \n",
    "        self.key_to_index = {word: i for i, word in enumerate(self.index_to_key)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(lst, n):\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "def pad_text(text: list, window_size: int, pad: str):\n",
    "    appendix = [pad] * window_size\n",
    "\n",
    "    return appendix + text + appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([34, 38, 19, 32, 24, 13, 40, 29, 14, 24, 46, 20, 30, 49, 26, 44, 33,\n",
       "       46, 46,  1])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(50, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 5), (1, 10))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(5)[np.newaxis, ...].shape, np.arange(10)[np.newaxis, ...].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "       [ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18],\n",
       "       [ 0,  3,  6,  9, 12, 15, 18, 21, 24, 27],\n",
       "       [ 0,  4,  8, 12, 16, 20, 24, 28, 32, 36]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(5)[..., np.newaxis] @ np.arange(10)[np.newaxis, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec(BaseEmbeddings):\n",
    "    def __init__(self, corpus, distinct_words=None, vector_size=100, window_size=5,\n",
    "                 min_count=10, batch_size=None, n_negative=5, n_epoches=5):\n",
    "        super().__init__(corpus, vector_size=vector_size, distinct_words=distinct_words, min_count=min_count)\n",
    "\n",
    "        self.V = torch.randn((len(self.index_to_key), vector_size))  # vocab_size, vector_size    #, device=torch.cuda.device(0))\n",
    "        self.U = torch.randn((len(self.index_to_key), vector_size))  # vocab_size, vector_size    #, device=torch.cuda.device(0))\n",
    "\n",
    "        # UNK, PAD = \"UNK\", \"PAD\"\n",
    "        # self.index_to_key = [UNK, PAD] + self.index_to_key\n",
    "\n",
    "        self.corpus = corpus\n",
    "        self.squeeze = list(chain.from_iterable(corpus))\n",
    "        self.window_size = window_size\n",
    "        self.batch_size = batch_size\n",
    "        if batch_size is None:\n",
    "            self.batch_size = np.max([len(text) for text in corpus])\n",
    "        self.n_negative = n_negative\n",
    "        self.alpha = 0.001\n",
    "        \n",
    "        self.train(n_epoches)\n",
    "        self.vectors = self.V\n",
    "    \n",
    "\n",
    "    def train(self, n_epoches=5):\n",
    "        \"\"\"\n",
    "        trains self.center_W and self.context_W matrices\n",
    "        \"\"\"\n",
    "        print(len(self.key_to_index), len(self.index_to_key))\n",
    "        for epoch in tqdm(range(n_epoches)):\n",
    "            for batch in chunks(self.squeeze, self.batch_size):\n",
    "                text = pad_text(batch, window_size=self.window_size, pad=\"UNK\")\n",
    "                for ind in range(len(text) - 2 * self.window_size): \n",
    "                    start = ind\n",
    "                    end = start + 2 * self.window_size\n",
    "                    w_j = start + self.window_size\n",
    "                    if text[w_j] in self.key_to_index.keys():\n",
    "                        for c in range(start, end + 1):\n",
    "                            if c != w_j and text[c] in self.key_to_index.keys():\n",
    "                                # print(self.key_to_index[text[w_j]], self.key_to_index[text[c]])\n",
    "                                # print(text[w_j], text[c])\n",
    "                                k_neg = np.random.choice(len(self.index_to_key), self.n_negative)  # take UNK PAD\n",
    "                                # print(torch.sigmoid(\n",
    "                                print(k_neg)\n",
    "                                # self.V[self.key_to_index[text[w_j]]\n",
    "                                U_k = self.U[k_neg]\n",
    "                                V_j = self.V[self.key_to_index[text[w_j]]]\n",
    "                                print((U_k @ V_j) * V_j)  # n_negative, vector_size x vector_size\n",
    "                                # self.np.random.choice(len(self.squeeze), self.n_negative)\n",
    "                        break\n",
    "\n",
    "\n",
    "                    # self.V -= self.alpha * dJ_dV\n",
    "                    # self.U -= self.alpha * dJ_dU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2 32  1 15 31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (5) must match the size of tensor b (100) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/sibwa19/documents/online_courses/nlp/nlp_courses_implementation/wiki_cs_hse_nlp/homeworks/01/word2vec.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/sibwa19/documents/online_courses/nlp/nlp_courses_implementation/wiki_cs_hse_nlp/homeworks/01/word2vec.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m w2v \u001b[39m=\u001b[39m Word2Vec(ru_corpus_cp, min_count\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n",
      "\u001b[1;32m/home/sibwa19/documents/online_courses/nlp/nlp_courses_implementation/wiki_cs_hse_nlp/homeworks/01/word2vec.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/sibwa19/documents/online_courses/nlp/nlp_courses_implementation/wiki_cs_hse_nlp/homeworks/01/word2vec.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_negative \u001b[39m=\u001b[39m n_negative\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/sibwa19/documents/online_courses/nlp/nlp_courses_implementation/wiki_cs_hse_nlp/homeworks/01/word2vec.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malpha \u001b[39m=\u001b[39m \u001b[39m0.001\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/sibwa19/documents/online_courses/nlp/nlp_courses_implementation/wiki_cs_hse_nlp/homeworks/01/word2vec.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain(n_epoches)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/sibwa19/documents/online_courses/nlp/nlp_courses_implementation/wiki_cs_hse_nlp/homeworks/01/word2vec.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvectors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mV\n",
      "\u001b[1;32m/home/sibwa19/documents/online_courses/nlp/nlp_courses_implementation/wiki_cs_hse_nlp/homeworks/01/word2vec.ipynb Cell 12\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/sibwa19/documents/online_courses/nlp/nlp_courses_implementation/wiki_cs_hse_nlp/homeworks/01/word2vec.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m         \u001b[39mprint\u001b[39m(k_neg)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/sibwa19/documents/online_courses/nlp/nlp_courses_implementation/wiki_cs_hse_nlp/homeworks/01/word2vec.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m         \u001b[39m# self.V[self.key_to_index[text[w_j]]\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/sibwa19/documents/online_courses/nlp/nlp_courses_implementation/wiki_cs_hse_nlp/homeworks/01/word2vec.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m         \u001b[39mprint\u001b[39m((\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mU[k_neg] \u001b[39m@\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mV[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkey_to_index[text[w_j]]]) \u001b[39m*\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mV[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkey_to_index[text[w_j]]])  \u001b[39m# n_negative, vector_size x vector_size\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/sibwa19/documents/online_courses/nlp/nlp_courses_implementation/wiki_cs_hse_nlp/homeworks/01/word2vec.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m         \u001b[39m# self.np.random.choice(len(self.squeeze), self.n_negative)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/sibwa19/documents/online_courses/nlp/nlp_courses_implementation/wiki_cs_hse_nlp/homeworks/01/word2vec.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (5) must match the size of tensor b (100) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "w2v = Word2Vec(ru_corpus_cp, min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['кстати',\n",
       " 'как',\n",
       " 'неожиданно',\n",
       " 'кпрф',\n",
       " 'становиться',\n",
       " 'не',\n",
       " 'все',\n",
       " 'равный',\n",
       " 'на',\n",
       " 'судьба',\n",
       " 'фермер',\n",
       " 'именно',\n",
       " 'накануне',\n",
       " 'выборы',\n",
       " 'можно',\n",
       " 'и',\n",
       " 'по',\n",
       " 'другому',\n",
       " 'сказать',\n",
       " 'убогий',\n",
       " 'клоунада',\n",
       " 'кпрф',\n",
       " 'это',\n",
       " 'попытка',\n",
       " 'отвечать',\n",
       " 'на',\n",
       " 'запрос',\n",
       " 'молодой',\n",
       " 'поколение',\n",
       " 'левый',\n",
       " 'не',\n",
       " 'питать',\n",
       " 'иллюзия',\n",
       " 'по',\n",
       " 'повод',\n",
       " 'коммунистический',\n",
       " 'номенклатура',\n",
       " 'советский',\n",
       " 'образец',\n",
       " 'но',\n",
       " 'в',\n",
       " 'сила',\n",
       " 'свой',\n",
       " 'положение',\n",
       " 'под',\n",
       " 'давление',\n",
       " 'вызов',\n",
       " 'время',\n",
       " 'они',\n",
       " 'вынуждать',\n",
       " 'быть',\n",
       " 'меняться',\n",
       " 'вот',\n",
       " 'он',\n",
       " 'тонкий',\n",
       " 'незаметный',\n",
       " 'ход',\n",
       " 'против',\n",
       " 'россия',\n",
       " 'зюганов',\n",
       " 'какой',\n",
       " 'же',\n",
       " 'жук',\n",
       " 'давать',\n",
       " 'пища',\n",
       " 'для',\n",
       " 'будущий',\n",
       " 'раздор',\n",
       " 'под',\n",
       " 'благовидный',\n",
       " 'предлог',\n",
       " 'прикрываться',\n",
       " 'бог',\n",
       " 'нет',\n",
       " 'слово',\n",
       " 'просто',\n",
       " 'в',\n",
       " 'этот',\n",
       " 'паблик',\n",
       " 'рано',\n",
       " 'подобный',\n",
       " 'пост',\n",
       " 'не',\n",
       " 'замечаться',\n",
       " 'видимо',\n",
       " 'с',\n",
       " 'непривычка',\n",
       " 'а',\n",
       " 'к',\n",
       " 'выходка',\n",
       " 'кпрф',\n",
       " 'я',\n",
       " 'уже',\n",
       " 'привыкать',\n",
       " 'не',\n",
       " 'реагировать',\n",
       " 'это',\n",
       " 'не',\n",
       " 'кпрф',\n",
       " 'это',\n",
       " 'цирк',\n",
       " 'коммунизм',\n",
       " 'это',\n",
       " 'совсем',\n",
       " 'другой',\n",
       " 'идеология',\n",
       " 'дибил',\n",
       " 'бл',\n",
       " 'почему',\n",
       " 'ведь',\n",
       " 'все',\n",
       " 'начинаться',\n",
       " 'с',\n",
       " 'низы',\n",
       " 'помнить',\n",
       " 'как',\n",
       " 'у',\n",
       " 'мы',\n",
       " 'заводской',\n",
       " 'секретарь',\n",
       " 'партия',\n",
       " 'все',\n",
       " 'рот',\n",
       " 'затыкать',\n",
       " 'когда',\n",
       " 'кто',\n",
       " 'то',\n",
       " 'хотеть',\n",
       " 'высказывать',\n",
       " 'свой',\n",
       " 'мнение',\n",
       " 'а',\n",
       " 'свой',\n",
       " 'сынок',\n",
       " 'назначать',\n",
       " 'секретарь',\n",
       " 'комсомольский',\n",
       " 'организатор',\n",
       " 'он',\n",
       " 'и',\n",
       " 'тогда',\n",
       " 'быть',\n",
       " 'еще',\n",
       " 'тот',\n",
       " 'прохиндей',\n",
       " 'сей',\n",
       " 'час',\n",
       " 'околачиваться',\n",
       " 'в',\n",
       " 'руководство',\n",
       " 'местный',\n",
       " 'отделение',\n",
       " 'кпрф',\n",
       " 'в',\n",
       " 'свой',\n",
       " 'время',\n",
       " 'в',\n",
       " 'место',\n",
       " 'с',\n",
       " 'папа',\n",
       " 'заниматься',\n",
       " 'какой',\n",
       " 'то',\n",
       " 'бизнес',\n",
       " 'тип',\n",
       " 'купить',\n",
       " 'продавать',\n",
       " 'опт',\n",
       " 'использовать',\n",
       " 'свой',\n",
       " 'связь',\n",
       " 'но',\n",
       " 'прогорать',\n",
       " 'в',\n",
       " 'бизнес',\n",
       " 'там',\n",
       " 'не',\n",
       " 'только',\n",
       " 'работать',\n",
       " 'там',\n",
       " 'пахать',\n",
       " 'надо',\n",
       " 'а',\n",
       " 'они',\n",
       " 'привыкать',\n",
       " 'жить',\n",
       " 'на',\n",
       " 'государственный',\n",
       " 'холява',\n",
       " 'вот',\n",
       " 'и',\n",
       " 'прогорать',\n",
       " 'теперь',\n",
       " 'в',\n",
       " 'кпрф',\n",
       " 'подвязываться',\n",
       " 'вот',\n",
       " 'писать',\n",
       " 'писать',\n",
       " 'а',\n",
       " 'потом',\n",
       " 'понимать',\n",
       " 'что',\n",
       " 'ты',\n",
       " 'видимо',\n",
       " 'не',\n",
       " 'понимать',\n",
       " 'суть',\n",
       " 'пост',\n",
       " 'во',\n",
       " 'первых',\n",
       " 'вспомнить',\n",
       " 'история',\n",
       " 'ссср',\n",
       " 'где',\n",
       " 'коммунист',\n",
       " 'постоянно',\n",
       " 'церковь',\n",
       " 'притесняться',\n",
       " 'а',\n",
       " 'если',\n",
       " 'и',\n",
       " 'поддерживаться',\n",
       " 'то',\n",
       " 'только',\n",
       " 'ради',\n",
       " 'выгода',\n",
       " 'партия',\n",
       " 'во',\n",
       " 'вторых',\n",
       " 'история',\n",
       " 'кпрф',\n",
       " 'идти',\n",
       " 'именно',\n",
       " 'оттуда',\n",
       " 'а',\n",
       " 'значит',\n",
       " 'что',\n",
       " 'они',\n",
       " 'ответственный',\n",
       " 'за',\n",
       " 'все',\n",
       " 'что',\n",
       " 'быть',\n",
       " 'и',\n",
       " 'подобный',\n",
       " 'поворот',\n",
       " 'на',\n",
       " '180',\n",
       " 'градус',\n",
       " 'это',\n",
       " 'лицемерие',\n",
       " 'в',\n",
       " 'третьих',\n",
       " 'сам',\n",
       " 'же',\n",
       " 'написать',\n",
       " 'это',\n",
       " 'его',\n",
       " 'личный',\n",
       " 'вопрос',\n",
       " 'на',\n",
       " 'который',\n",
       " 'не',\n",
       " 'должно',\n",
       " 'влиять',\n",
       " 'государство',\n",
       " 'а',\n",
       " 'теперь',\n",
       " 'прочитывать',\n",
       " 'что',\n",
       " 'написать',\n",
       " 'в',\n",
       " 'пост',\n",
       " 'он',\n",
       " 'хотеть',\n",
       " 'чтобы',\n",
       " 'это',\n",
       " 'быть',\n",
       " 'не',\n",
       " 'личный',\n",
       " 'вопрос',\n",
       " 'каждый',\n",
       " 'а',\n",
       " 'чтобы',\n",
       " 'государство',\n",
       " 'на',\n",
       " 'это',\n",
       " 'влиять',\n",
       " 'так',\n",
       " 'вариант',\n",
       " 'два',\n",
       " 'зюганов',\n",
       " 'или',\n",
       " 'оральный',\n",
       " 'кто',\n",
       " 'еще',\n",
       " 'мочь',\n",
       " 'вселять',\n",
       " 'надежда',\n",
       " 'о',\n",
       " 'сладкий',\n",
       " 'будущий',\n",
       " 'жизнь',\n",
       " 'чтобы',\n",
       " 'овощ',\n",
       " 'в',\n",
       " 'это',\n",
       " 'поверять']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
